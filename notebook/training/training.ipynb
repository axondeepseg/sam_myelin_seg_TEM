{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b54e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../scripts')\n",
    "import bids_utils\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "from segment_anything.utils.transforms import ResizeLongestSide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('../../data_axondeepseg_tem/')\n",
    "derivatives_path = Path('../../scripts/derivatives')\n",
    "embeddings_path = derivatives_path / 'embeddings'\n",
    "maps_path = derivatives_path / 'maps'\n",
    "\n",
    "data_dict = bids_utils.index_bids_dataset(datapath)\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions to read prompts and labels\n",
    "# %matplotlib inline\n",
    "def get_sample_bboxes(subject, sample, maps_path):\n",
    "    prompts_fname = maps_path / subject / 'micr' / f'{subject}_{sample}_prompts.csv'\n",
    "    prompts_df = pd.read_csv(prompts_fname)\n",
    "    return prompts_df[['bbox_min_x', 'bbox_min_y', 'bbox_max_x', 'bbox_max_y']]\n",
    "\n",
    "def get_myelin_bbox(bbox_df, axon_id):\n",
    "    return np.array(bbox_df.iloc[axon_id])\n",
    "\n",
    "def get_myelin_map(subject, sample, maps_path):\n",
    "    map_fname = maps_path / subject / 'micr' / f'{subject}_{sample}_myelinmap.png'\n",
    "    return cv2.imread(str(map_fname))\n",
    "    \n",
    "def get_myelin_mask(myelin_map, axon_id):\n",
    "    return 255 * (myelin_map == axon_id + 1)\n",
    "\n",
    "# helper functions to display masks/bboxes\n",
    "def show_mask(mask, ax):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d79e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader providing the myelin map (masks), the bboxes (prompts) \n",
    "# and the path to the pre-computed image embeddings\n",
    "def bids_dataloader(data_dict, maps_path, embeddings_path):\n",
    "    subjects = list(data_dict.keys())\n",
    "    # we keep the last subject for testing\n",
    "    for sub in subjects[:-1]:\n",
    "        samples = (s for s in data_dict[sub].keys() if 'sample' in s)\n",
    "        for sample in samples:\n",
    "            emb_path = embeddings_path / sub / 'micr' / f'{sub}_{sample}_TEM_embedding.pt'\n",
    "            bboxes = get_sample_bboxes(sub, sample, maps_path)\n",
    "            myelin_map = get_myelin_map(sub, sample, maps_path)\n",
    "            yield (emb_path, bboxes, myelin_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'vit_b'\n",
    "checkpoint = '../../scripts/sam_vit_b_01ec64.pth'\n",
    "device = 'cuda:3'\n",
    "\n",
    "sam_model = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "sam_model.to(device)\n",
    "sam_model.train();\n",
    "\n",
    "def load_image_embedding(path):\n",
    "    emb_dict = torch.load(path, device)\n",
    "    return emb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436843d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-7\n",
    "wd = 0\n",
    "optimizer = torch.optim.Adam(sam_model.mask_decoder.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "loss_fn = monai.losses.DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43a50d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import threshold, normalize\n",
    "\n",
    "num_epochs = 40\n",
    "batch_size = 10\n",
    "losses = []\n",
    "transform = ResizeLongestSide(sam_model.image_encoder.img_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "    data_loader = bids_dataloader(data_dict, maps_path, embeddings_path)\n",
    "    \n",
    "    pbar = tqdm(total=158)\n",
    "    for sample in data_loader:\n",
    "        emb_path, bboxes, myelin_map = sample\n",
    "        emb_dict = load_image_embedding(emb_path)\n",
    "        original_size = emb_dict['original_size']\n",
    "        input_size = emb_dict['input_size']\n",
    "        image_embedding = emb_dict['features']\n",
    "        \n",
    "        if 'sub-nyuMouse28_sample-0006' in str(emb_path):\n",
    "            # figure to plot all predictions\n",
    "            plt.figure(figsize=(10, 10))\n",
    "        \n",
    "        # train on every axon in the image\n",
    "        for axon_id in range(len(bboxes)):\n",
    "            # get mask and bbox prompt\n",
    "            prompt = get_myelin_bbox(bboxes, axon_id)\n",
    "            gt_mask = get_myelin_mask(myelin_map, axon_id)\n",
    "            \n",
    "            # empty masks should not be processed\n",
    "            if np.isnan(prompt).any():\n",
    "                continue\n",
    "                \n",
    "            # no grad for the prompt encoder\n",
    "            with torch.no_grad():\n",
    "                box = transform.apply_boxes(prompt, original_size)\n",
    "                box_torch = torch.as_tensor(box, dtype=torch.float, device=device)\n",
    "                box_torch = box_torch[None, :]\n",
    "                \n",
    "                sparse_embeddings, dense_embeddings = sam_model.prompt_encoder(\n",
    "                    points=None,\n",
    "                    boxes=box_torch,\n",
    "                    masks=None,\n",
    "                )\n",
    "            # now we pass the image and prompt embeddings in the mask decoder\n",
    "            low_res_mask, iou_predictions = sam_model.mask_decoder(\n",
    "                image_embeddings=image_embedding,\n",
    "                image_pe=sam_model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparse_embeddings,\n",
    "                dense_prompt_embeddings=dense_embeddings,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "            \n",
    "            upscaled_mask = sam_model.postprocess_masks(\n",
    "                low_res_mask,\n",
    "                input_size,\n",
    "                original_size,\n",
    "            ).to(device)\n",
    "            binary_mask = normalize(threshold(upscaled_mask, 0.0, 0))\n",
    "            \n",
    "            gt_mask_resized = torch.from_numpy(gt_mask[:,:,0]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            gt_binary_mask = torch.as_tensor(gt_mask_resized > 0, dtype=torch.float32)\n",
    "            \n",
    "            loss = loss_fn(binary_mask, gt_binary_mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "            if 'sub-nyuMouse28_sample-0006' in str(emb_path):\n",
    "                show_mask(binary_mask.cpu().detach().numpy().squeeze(), plt.gca())\n",
    "        pbar.update(1)\n",
    "        if 'sub-nyuMouse28_sample-0006' in str(emb_path):\n",
    "            plt.axis('off')\n",
    "            plt.savefig(f'predictions_epoch_{epoch}')\n",
    "    losses.append(epoch_losses)\n",
    "    print(f'EPOCH {epoch} MEAN LOSS: {np.mean(epoch_losses)}')\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(sam_model.state_dict(), f'../../scripts/sam_vit_b_01ec64_epoch_{epoch}_diceloss.pth')\n",
    "    \n",
    "torch.save(sam_model.state_dict(), '../../scripts/sam_vit_b_01ec64_finetuned_diceloss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_losses = [np.mean(x) for x in losses]\n",
    "mean_losses\n",
    "\n",
    "plt.plot(list(range(len(mean_losses))), mean_losses)\n",
    "plt.title('Mean epoch loss')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.savefig('losses_with_diceloss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
